{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59e3136a",
   "metadata": {},
   "source": [
    "# Obj: Create a shakespearean text generation using simple markov chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4930f6f3",
   "metadata": {},
   "source": [
    "Inspired by this youtube [video](https://www.youtube.com/watch?v=E4WcBWuQQws&ab_channel=NormalizedNerd) By Normalized Nerd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ab3e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560a10e5",
   "metadata": {},
   "source": [
    "The corpuses are 375 poems by William Shakespeare that are scraped from this [website](https://www.williamshakespeare.net/poems.jsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a9d72",
   "metadata": {},
   "source": [
    "### Scrape the links to each poem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6df6e92",
   "metadata": {},
   "source": [
    "The poems are located in a dedicated page. I will scrape the link to those page from the main page. To do that, Selenium will be needed as an interaction with the web is necessary. After obtaining the link, I will just use request and beautiful soup as they are much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "551f999c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WEBSITE = \"https://www.williamshakespeare.net/poems.jsp\"\n",
    "cService = webdriver.ChromeService(\"../chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service = cService)\n",
    "driver.get(WEBSITE)\n",
    "\n",
    "# Expand the number of shown links in the main page\n",
    "options = driver.find_elements(By.TAG_NAME, \"option\")\n",
    "last_option = options[-1]  # picking the last option (100)\n",
    "last_option.click()\n",
    "\n",
    "links = []\n",
    "for i in range(1, 5):  # Loop across the pages where the links are stored\n",
    "    rows = driver.find_elements(By.CLASS_NAME, 'sorting_1')\n",
    "    for row in rows:\n",
    "        content = row.find_element(By.TAG_NAME, \"a\")\n",
    "        link = content.get_attribute(\"href\")\n",
    "        links.append(link)\n",
    "    if i < 4:  # Click the next page a long a it is not the last page\n",
    "        next_ = driver.find_element(By.ID, 'poem_table_next')\n",
    "        next_.click()\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528defc5",
   "metadata": {},
   "source": [
    "### Scrape the raw html page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf887896",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_html = []\n",
    "for i in links:\n",
    "    req = requests.get(i)\n",
    "    raw_html.append(req.text)  # obtained the links to each poem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed687de3",
   "metadata": {},
   "source": [
    "### Cleaning and combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "655aa787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # This particular function is generated by ChatGPT :p.\n",
    "    # Sadly, my regex sucks hahaha\n",
    "    \n",
    "    roman_pattern = r'\\b[IVXLCDM]+\\b'\n",
    "\n",
    "    # Use re.sub() to replace Roman numerals with an empty string\n",
    "    cleaned_text = re.sub(roman_pattern, '', text)\n",
    "    \n",
    "    # Remove excessive whitespace and newline characters\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()  # extra space is fine (theres split)\n",
    "    \n",
    "    # Remove punctuation characters using regex pattern\n",
    "    cleaned_text = cleaned_text.replace(\"'\", \"\")\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', ' ', cleaned_text)    \n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def preprocessing(x):\n",
    "    # converting raw html to soup object and return the cleaned text for each poem\n",
    "    \n",
    "    soup = BeautifulSoup(x, \"html.parser\")\n",
    "    raw_text = soup.find(\"p\").get_text(\"\\n\")\n",
    "    cleaned_text = str.lower(clean_text(raw_text))\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06df951",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "92941221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_text = [preprocessing(i) for i in raw_html]\n",
    "final_text = \" \".join(final_text).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "13f47c2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of token: 54227\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of token: {len(final_text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3c1062",
   "metadata": {},
   "source": [
    "### The Markov Chain Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9838f8e8",
   "metadata": {},
   "source": [
    "In this model, each ngram can be considered as a state, each with connections to other ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "263a10dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovChainNLP():\n",
    "    \n",
    "    def generate_ngram(self, text, n):\n",
    "        ngrams = []\n",
    "        nwords = len(text)\n",
    "        for i in range(nwords - n + 1):\n",
    "            gram  = tuple(text[i:i + n])\n",
    "            ngrams.append(gram)\n",
    "        return ngrams\n",
    "    \n",
    "    def get_probability(self, transition):\n",
    "        # converting the connections into probability\n",
    "        \n",
    "        for i in transition.keys():\n",
    "            sum_1 = sum(transition[i].values())  # sum of connection for each state\n",
    "            for j in transition[i].keys():\n",
    "                transition[i][j] = transition[i][j]/sum_1  # dividing by the sum of connection\n",
    "        return transition          \n",
    "\n",
    "    def fit(self, text, n_ngram):\n",
    "        transition = {}\n",
    "        ngrams = self.generate_ngram(text, n_ngram)\n",
    "        for i in range(len(ngrams) - 1):\n",
    "            current = ngrams[i]\n",
    "            next_ = ngrams[i+1]\n",
    "\n",
    "            if current not in transition.keys():  # add new state\n",
    "                transition[current] = {}\n",
    "                transition[current][next_] = 1\n",
    "            else:\n",
    "                if next_ in transition[current].keys():  # add the next_state's occurence\n",
    "                    transition[current][next_] += 1\n",
    "                else:\n",
    "                    transition[current][next_] = 1  # add new next_state\n",
    "        \n",
    "        self.transition = self.get_probability(transition)\n",
    "        \n",
    "    def predict(self, prompt, limit):\n",
    "        prediction = \"\" + prompt + \" \"\n",
    "        X = tuple(prompt.split())\n",
    "        \n",
    "        for i in range(limit):\n",
    "            curr_choices = self.transition[X]\n",
    "            chosen_idx = np.random.choice(len(curr_choices), \n",
    "                                          p=list(curr_choices.values())) # random choice with probability\n",
    "            raw_result = list(curr_choices.keys())[chosen_idx]\n",
    "            prediction += raw_result[1] + \" \"  # only pick one word from each ngram (after the current word)\n",
    "            X = raw_result\n",
    "        \n",
    "        return prediction\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc8d68d",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "116cab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MarkovChainNLP()\n",
    "model.fit(final_text, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "51220d6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of states: 22617\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of states: {len(model.transition)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741db11d",
   "metadata": {},
   "source": [
    "### Finding the prompt (initial ngram) that has the most connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "92c17f36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smallest: 0.00847457627118644\n",
      "prompt: ('in', 'the')\n",
      "\n",
      "second_smallest: 0.029411764705882353\n",
      "second_prompt: ('in', 'their')\n"
     ]
    }
   ],
   "source": [
    "smallest = 1\n",
    "\n",
    "prompt = None\n",
    "\n",
    "second_smallest = 1\n",
    "second_prompt = None\n",
    "\n",
    "for i in model.transition:\n",
    "    for j in model.transition[i]:\n",
    "        if model.transition[i][j]<smallest:\n",
    "            second_smallest = smallest\n",
    "            second_prompt = prompt\n",
    "            smallest = model.transition[i][j]\n",
    "            prompt = i\n",
    "            \n",
    "print(f\"smallest: {smallest}\")\n",
    "print(f\"prompt: {prompt}\")\n",
    "print()\n",
    "print(f\"second_smallest: {second_smallest}\")\n",
    "print(f\"second_prompt: {second_prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a099659f",
   "metadata": {},
   "source": [
    "### Prompt: \"in the\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "cafd639f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : in the breath of words respect me for thee hence o that \n",
      "2 : in the very worst of fortunes might and other strains of woe \n",
      "3 : in the midst of all too near sin of self doing crime \n",
      "4 : in the living record of your desire have no end mine appetite \n",
      "5 : in the caldron boil and bake eye of heaven better becomes the \n",
      "6 : in the bay where all thy might is more than have spent \n",
      "7 : in the bud and vaded in the dark liver of blaspheming jew \n",
      "8 : in the west which by lacking have supposèd dead and there and \n",
      "9 : in the west which by lacking have supposed dead and drowsy fire \n",
      "10 : in the breath that from him there sap checked with frost and \n",
      "11 : in the vault to whose sound chaste wings obey but thou wilt \n",
      "12 : in the suffering pangs it bears as often shrieking undistinguishd woe in \n",
      "13 : in the praise thereof spends all his face love lackd a dwelling \n",
      "14 : in the brain that ink may character which hath no exchequer now \n",
      "15 : in the world or else of thee this prognosticate thy end is \n",
      "16 : in the brain that ink may character which hath not made for \n",
      "17 : in the spring when was certain oer incertainty crowning the present nor \n",
      "18 : in the spring farewell god knows when we shall meet again have \n",
      "19 : in the spring and foison of the east my heart think that \n",
      "20 : in the very part was consecrate to thee tell the face thou \n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 21):\n",
    "    print(f\"{i} : {model.predict('in the', 10)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3505bbd1",
   "metadata": {},
   "source": [
    "### Prompt: \"in their\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0d2f140d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : in their glory die the earth can yield me but yet thou \n",
      "2 : in their gold coats spots you see those be rubies fairy favours \n",
      "3 : in their youthful sap at height decrease and wear their brave state \n",
      "4 : in their garments though new fangled ill some in their pride lies \n",
      "5 : in their wills obey many there were that did not better for \n",
      "6 : in their birth and where they grew was it his spirit by \n",
      "7 : in their glory die the world to say it is an ever \n",
      "8 : in their wealth some in their smells alone but in the churchway \n",
      "9 : in their youthful sap at height decrease and wear their brave state \n",
      "10 : in their garments though new fangled ill some in their glory die \n",
      "11 : in their hawks and hounds some in their birth some in their \n",
      "12 : in their hue encloses o father what a torment thrice threefold thus \n",
      "13 : in their glory die the earth can have but earth which is \n",
      "14 : in their smells alone but in my sight where wasteful time debateth \n",
      "15 : in their wealth some in their glory die the earth devour her \n",
      "16 : in their glory die the world doth spend shifts but his place \n",
      "17 : in their rotten smoke tis not enough that through the wild air \n",
      "18 : in their bodys force some in their hawks and hounds some in \n",
      "19 : in their flowing cups freshly remembred this story shall the good man \n",
      "20 : in their horse and every humour hath his adjunct pleasure wherein it \n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 21):\n",
    "    print(f\"{i} : {model.predict('in their', 10)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca7c63e",
   "metadata": {},
   "source": [
    "### Not bad :p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadc97b4",
   "metadata": {},
   "source": [
    "- Well, some sentences make sense, but most dont hahaha. Then again, poems are not meant to be 100% understood anyway. Let's just say the generated text are meant to be felt, not understood :p haha. \n",
    "- Perhaps it's a bad idea to use markov chain on poem as poems are very lenient in terms of grammar and vocabularies, hence a pattern becomes hard to detect. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
