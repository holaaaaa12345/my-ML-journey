{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02737cbd",
   "metadata": {},
   "source": [
    "# Neural network learning from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c588d68a",
   "metadata": {},
   "source": [
    "This notebook is a part of the series __From Scratch__, where i try to code machine learning algorithms from scratch (just numpy and math)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7a2fbf",
   "metadata": {},
   "source": [
    "This is a major milestone during my self-taught machine learning journey. Understanding the backpropagation and calculus in it is quite an experience. That said, this is really the simplest implementation :p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "285ac7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential  # Used for crosschecking\n",
    "from tensorflow.keras.layers import Dense, Normalization\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid, softmax\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df75c1df",
   "metadata": {},
   "source": [
    "### Objective: Determine a tumor's malignancy given its texture_mean and radius_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9e7e12",
   "metadata": {},
   "source": [
    "#### The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c8caac3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>radius_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.38</td>\n",
       "      <td>17.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17.77</td>\n",
       "      <td>20.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>21.25</td>\n",
       "      <td>19.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>20.38</td>\n",
       "      <td>11.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>14.34</td>\n",
       "      <td>20.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>1</td>\n",
       "      <td>22.39</td>\n",
       "      <td>21.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1</td>\n",
       "      <td>28.25</td>\n",
       "      <td>20.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1</td>\n",
       "      <td>28.08</td>\n",
       "      <td>16.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1</td>\n",
       "      <td>29.33</td>\n",
       "      <td>20.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0</td>\n",
       "      <td>24.54</td>\n",
       "      <td>7.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis  texture_mean  radius_mean\n",
       "0            1         10.38        17.99\n",
       "1            1         17.77        20.57\n",
       "2            1         21.25        19.69\n",
       "3            1         20.38        11.42\n",
       "4            1         14.34        20.29\n",
       "..         ...           ...          ...\n",
       "564          1         22.39        21.56\n",
       "565          1         28.25        20.13\n",
       "566          1         28.08        16.60\n",
       "567          1         29.33        20.60\n",
       "568          0         24.54         7.76\n",
       "\n",
       "[569 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./datasets/bdiag.csv\")[[\"diagnosis\", \"texture_mean\", \"radius_mean\"]]\n",
    "df[\"diagnosis\"] = df[\"diagnosis\"].replace({\"M\":1, \"B\":0})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df5d58c",
   "metadata": {},
   "source": [
    "#### Plotting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0da2e048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "mal = df[df[\"diagnosis\"]==1]\n",
    "ben = df[df[\"diagnosis\"]==0]\n",
    "\n",
    "ax.scatter(mal[\"texture_mean\"], mal[\"radius_mean\"], label=\"malignant\", c=\"r\", alpha=0.5)\n",
    "ax.scatter(ben[\"texture_mean\"], ben[\"radius_mean\"], label=\"benign\", c=\"b\", alpha=0.5)\n",
    "ax.set_xlabel(\"texture_mean\")\n",
    "ax.set_ylabel(\"radius_mean\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b14c8ff",
   "metadata": {},
   "source": [
    "Looks like the texture_mean does not have much influence on malignancy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b617ade",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b641944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"texture_mean\", \"radius_mean\"]].values\n",
    "y = df[\"diagnosis\"].values.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b827b2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (455, 2)\n",
      "Y_train: (455, 1)\n",
      "X_test:  (114, 2)\n",
      "Y_test:  (114, 1)\n"
     ]
    }
   ],
   "source": [
    "print('X_train: ' + str(X_train.shape))\n",
    "print('Y_train: ' + str(y_train.shape))\n",
    "print('X_test:  '  + str(X_test.shape))\n",
    "print('Y_test:  '  + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca568a5",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbfafdc",
   "metadata": {},
   "source": [
    "predict only based on the mean of radius_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02168e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accuracy:0.895\n"
     ]
    }
   ],
   "source": [
    "# Training the mean of radius_mean\n",
    "rad_mean_train = X_train[:, [1]]\n",
    "mean = rad_mean_train.mean()\n",
    "\n",
    "# Testing on the testing set\n",
    "rad_mean_test = X_test[:, [1]]\n",
    "diag = y_test\n",
    "pred = np.where(rad_mean_test>mean, 1, 0)\n",
    "result = (pred==diag).mean()\n",
    "\n",
    "print(f\"baseline accuracy:{result:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7056c1",
   "metadata": {},
   "source": [
    "### Feature normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c85e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = Normalization(axis=1)\n",
    "norm.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d033f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(norm(X_train))  # converts back to numpy because tensor is slower\n",
    "X_test = np.array(norm(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63535d4f",
   "metadata": {},
   "source": [
    "### The Model overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cce2cc6",
   "metadata": {},
   "source": [
    "![alt text](.\\datasets\\model_nn_scratch.jpg \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1324519",
   "metadata": {},
   "source": [
    "## Doing it the \"easy\" way using keras sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95555dbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1742c773e80>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    \n",
    "    Dense(units=2, activation=relu),\n",
    "    Dense(units=1, activation=linear)\n",
    "])\n",
    "\n",
    "model.compile(loss=BinaryCrossentropy(from_logits=True),  # to avoid numerical instability\n",
    "              optimizer=Adam(learning_rate=0.01),\n",
    "              metrics=\"accuracy\"\n",
    "             )\n",
    "model.fit(X_train, y_train, epochs=80, verbose=0)  # verbose = 0 to avoid printing too much"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5610e0c6",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4df90265",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2254 - accuracy: 0.9211\n",
      "total cost: 0.225\n",
      "accuracy: 0.921\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_test, y_test)\n",
    "print(f\"total cost: {result[0]:.3f}\")\n",
    "print(f\"accuracy: {result[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf855c6c",
   "metadata": {},
   "source": [
    "# Doing it the hard way (from scratch)\n",
    "Let's start with the math behind neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7843ec1c",
   "metadata": {},
   "source": [
    "#### The specified architecture\n",
    "2 features --> 1 hidden layer (2 neuron relu) --> 1 output layer (1 neuron sigmoid)\n",
    "\n",
    "#### Notation\n",
    "$z_{1}^{[1]} =$ linear combination of input (feature) to the first neuron of the first layer <br>\n",
    "$z_{2}^{[1]} =$ linear combination of input (feature) to the second neuron of the first layer <br>\n",
    "\n",
    "$a_{1}^{[1]} =$ output of the first neuron of the first layer<br>\n",
    "$a_{2}^{[1]} =$ output of the second neuron of the first layer<br>\n",
    "\n",
    "$z^{[2]} =$ linear combination of output of the first layer<br>\n",
    "$a^{[2]} =$ output of the only neuron of the second layer (final output)<br>\n",
    "\n",
    "name for each parameters can be seen on the model overview above\n",
    "\n",
    "#### Forward propagation:\n",
    "\n",
    "$$z_{1}^{[1]} = w_{1}^{[1]}x_{1} + w_{2}^{[1]}x_{2} + b_{1}^{[1]} $$ <br>\n",
    "$$z_{2}^{[1]} = w_{3}^{[1]}x_{1} + w_{4}^{[1]}x_{2} + b_{2}^{[1]} $$ <br>\n",
    "$$a_{1}^{[1]} = \\text{relu}(z_{1}^{[1]})$$ <br>\n",
    "$$a_{2}^{[1]} = \\text{relu}(z_{2}^{[1]})$$ <br>\n",
    "$$z^{[2]} = w_{1}^{[2]}x_{1} + w_{2}^{[2]}x_{2} + b^{[2]} $$ <br>\n",
    "$$a^{[2]} = \\frac{1}{1 + e^{-z^{[2]}}}$$ <br>\n",
    "\n",
    "#### cost & loss function: <br>\n",
    "$$\\text{cross entropy cost}(\\hat{a}^{[2]}, \\hat{y}) = -\\frac{1}{n}\\sum_{i=1}^{n}\\sum_{j=1}^{m}y_{ij}\\text{log}(a^{[2]}[ij]) \\space\\text{where n=number of examples, m=number of class}$$ <br>\n",
    "$$\\text{binary cross entropy cost}(\\hat{a}^{[2]}, \\hat{y}) = -\\frac{1}{n}\\sum_{i=1}^{n}y_{i}\\text{log}(a^{[2]}[i]) + (1-y_{i})\\text{log}(1-a^{[2]}[i])$$ <br>\n",
    "\n",
    "#####  Derivative of cost function w.r.t parameters\n",
    "$$\\frac{\\partial ( \\text{binary cross entropy cost}(\\vec{a}^{[2]}, \\vec{y}))}{\\partial \\vec{w}} = \\frac{1}{n}(\\frac {\\partial (\\text{binary cross entropy loss}(a^{[2]}, \\hat{y}))_{1}}{\\partial \\vec{w}} + \\frac {\\partial (\\text{binary cross entropy loss}(a^{[2]}, \\hat{y}))_{2}}{\\partial \\vec{w}}+ ...+ \\frac {\\partial (\\text{binary cross entropy loss}(a^{[2]}, \\hat{y}))_{n}}{\\partial \\vec{w}})\\space \\text{for n=number of examples}$$<br>\n",
    "\n",
    "$$\\text{binary cross entropy loss}(a^{[2]}, \\hat{y}) = -(y_{i}\\text{log}(a^{[2]}) + (1-y_{i})\\text{log}(1-a^{[2]}))$$\n",
    "\n",
    "- Intuitively speaking, the gradient of cost function wrt to parameter $w$ is the average of all the gradient of loss function wrt to parameter $w_{1}, w_{2},..., w_{n}$ where $n=$number of examples.\n",
    "\n",
    "\n",
    "#### Backward propagation:\n",
    "- The point of backpropagation is to determine the gradient of cost function wrt to each parameter $w$\n",
    "- Backpropagation involves the derivation of loss function wrt to each parameters, then averaging them later for gradient descent\n",
    "\n",
    "##### output layer\n",
    "$\\frac{\\partial \\text{cost}(a^{[2]})}{\\partial z^{[2]}}=\\frac{\\partial a^{[2]}}{\\partial z^{[2]}}\\times\\frac{\\partial\\text{cost}(a^{[2]})}{\\partial a^{[2]}} = (1-a^{[2]})\\times \\frac{a^{[2]}-y}{a^{[2]}(1-a^{[2]})} = a^{[2]} - y$\n",
    "\n",
    "\n",
    "$$\\frac{\\partial\\text{cost}(a^{[2]})}{\\partial w_{1}^{[2]}} = \\frac{\\partial z^{[2]}}{\\partial w_{1}^{[2]}}\\times\\frac{\\partial \\text{cost}(a^{[2]})}{\\partial z^{[2]}} = a_{1}^{[1]}\\times (a^{[2]} - y)$$\n",
    "\n",
    "$$\\frac{\\partial\\text{cost}(a^{[2]})}{\\partial w_{2}^{[2]}} = \\frac{\\partial z^{[2]}}{\\partial w_{2}^{[2]}}\\times\\frac{\\partial \\text{cost}(a^{[2]})}{\\partial z^{[2]}} = a_{2}^{[1]}\\times (a^{[2]} - y)$$\n",
    "\n",
    "$$\\frac{\\partial\\text{cost}(a^{[2]})}{\\partial b^{[2]}} = \\frac{\\partial z^{[2]}}{\\partial b^{[2]}}\\times\\frac{\\partial \\text{cost}(a^{[2]})}{\\partial z^{[2]}} = a^{[2]} - y$$\n",
    "\n",
    "\n",
    "##### hidden layer\n",
    "$\\frac{\\partial \\text{cost}(a^{[2]})}{\\partial z_{1}^{[1]}}=\\frac{\\partial a_{1}^{[1]}}{\\partial z_{1}^{[1]}}\\times\\frac{\\partial z^{[2]}}{\\partial a_{1}^{[1]}}\\times\\frac{\\partial \\text{cost}(a^{[2]})}{\\partial z^{[2]}} = \\text{relu'}(z_1^{[1]}) \\times w_1^{[2]}\\times (a^{[2]} - y)$ <br>\n",
    "\n",
    "$$\\frac{\\partial\\text{cost}(a^{[2]})}{\\partial w_{1}^{[1]}} = \\frac{\\partial z_{1}^{[1]}}{\\partial w_{1}^{[1]}}\\times \\frac{\\partial \\text{cost}(a^{[2]})}{\\partial z_{1}^{[1]}} = x_1\\times \\text{relu'}(z_1^{[1]}) \\times w_1^{[2]}\\times (a^{[2]} - y)$$\n",
    "$$\\frac{\\partial\\text{cost}(a^{[2]})}{\\partial w_{2}^{[1]}} = \\frac{\\partial z_{1}^{[1]}}{\\partial w_{2}^{[1]}}\\times \\frac{\\partial \\text{cost}(a^{[2]})}{\\partial z_{1}^{[1]}} = x_2\\times \\text{relu'}(z_1^{[1]}) \\times w_1^{[2]}\\times (a^{[2]} - y)$$ \n",
    "$$\\frac{\\partial\\text{cost}(a^{[2]})}{\\partial b_{1}^{[1]}} = \\frac{\\partial z_{1}^{[1]}}{\\partial b_{1}^{[1]}}\\times \\frac{\\partial \\text{cost}(a^{[2]})}{\\partial z_{1}^{[1]}} = \\text{relu'}(z_1^{[1]}) \\times w_1^{[2]}\\times (a^{[2]} - y)$$ \n",
    "<br>\n",
    "\n",
    "$\\frac{\\partial \\text{cost}(a^{[2]})}{\\partial z_{2}^{[1]}}=\\frac{\\partial a_{1}^{[1]}}{\\partial z_{2}^{[1]}}\\times\\frac{\\partial z^{[2]}}{\\partial a_{1}^{[1]}}\\times\\frac{\\partial \\text{cost}(a^{[2]})}{\\partial z^{[2]}} = \\text{relu'}(z_2^{[1]}) \\times w_2^{[2]}\\times (a^{[2]} - y)$ <br>\n",
    "\n",
    "$$\\frac{\\partial\\text{cost}(a^{[2]})}{\\partial w_{3}^{[1]}} = \\frac{\\partial z_{2}^{[1]}}{\\partial w_{3}^{[1]}}\\times \\frac{\\partial \\text{cost}(a^{[2]})}{\\partial z_{1}^{[1]}} = x_1\\times \\text{relu'}(z_2^{[1]}) \\times w_2^{[2]}\\times (a^{[2]} - y)$$\n",
    "$$\\frac{\\partial\\text{cost}(a^{[2]})}{\\partial w_{4}^{[1]}} = \\frac{\\partial z_{1}^{[1]}}{\\partial w_{4}^{[1]}}\\times \\frac{\\partial \\text{cost}(a^{[2]})}{\\partial z_{1}^{[1]}} = x_2\\times \\text{relu'}(z_1^{[1]}) \\times w_1^{[2]}\\times (a^{[2]} - y)$$ \n",
    "$$\\frac{\\partial\\text{cost}(a^{[2]})}{\\partial b_{2}^{[1]}} = \\frac{\\partial z_{1}^{[1]}}{\\partial b_{2}^{[1]}}\\times \\frac{\\partial \\text{cost}(a^{[2]})}{\\partial z_{1}^{[1]}} = \\text{relu'}(z_1^{[1]}) \\times w_1^{[2]}\\times (a^{[2]} - y)$$ \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f41c1db",
   "metadata": {},
   "source": [
    "### No vectorization (just for loop), vanilla gradient descent, and non-modular implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7782d8bb",
   "metadata": {},
   "source": [
    "This implementation is tailored for learning, hence not for production usage. It is meant to be explicit and not use any vectorization. It is also non-modular, as it can only be of the specified architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9564fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    \n",
    "    def initialize(self):\n",
    "        self.w11, self.w12, self.w13, self.w14, self.w21, self.w22, self.b11, self.b12, self.b2 = np.random.randn(9)\n",
    "    \n",
    "    def relu(self, x):\n",
    "        return np.maximum(x, 0)\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def binary_cross_entropy(self, x, y_true):\n",
    "        return -(y_true * np.log(x) + (1 - y_true) * np.log(1 - x))\n",
    "    \n",
    "    def derivative_relu(self, x):\n",
    "        return 1 if x>0 else 0\n",
    "    \n",
    "    def forward_prop(self, x1, x2):\n",
    "        forward_dict = {} \n",
    "        \n",
    "        # hidden layer\n",
    "        forward_dict[\"z11\"] = self.w11 * x1 + self.w12 * x2 + self.b11\n",
    "        forward_dict[\"z12\"] = self.w13 * x1 + self.w14 * x2 + self.b12\n",
    "        forward_dict[\"a11\"] = self.relu(forward_dict[\"z11\"])\n",
    "        forward_dict[\"a12\"] = self.relu(forward_dict[\"z12\"])\n",
    "        \n",
    "        # output layer\n",
    "        forward_dict[\"z2\"] = self.w21 * forward_dict[\"a11\"] + self.w22 * forward_dict[\"a12\"] + self.b2\n",
    "        forward_dict[\"a2\"] = self.sigmoid(forward_dict[\"z2\"])\n",
    "        \n",
    "        return forward_dict\n",
    "\n",
    "    def back_prop(self, x1, x2, y_true, forward_dict):\n",
    "        # gradient will be calculated for each training example and averaged later#\n",
    "        \n",
    "        deriva_dict = {}\n",
    "        \n",
    "        # output layer\n",
    "        error = forward_dict[\"a2\"] - y_true\n",
    "        \n",
    "        deriva_dict[\"dloss_dw21\"] = forward_dict[\"a11\"] * error\n",
    "        deriva_dict[\"dloss_dw22\"] = forward_dict[\"a12\"] * error\n",
    "        deriva_dict[\"dloss_db2\"] = error\n",
    "        \n",
    "        # hidden layer\n",
    "        dcost_dz11 = self.derivative_relu(forward_dict[\"z11\"]) * self.w21 * error\n",
    "        dcost_dz12 = self.derivative_relu(forward_dict[\"z12\"]) * self.w22 * error\n",
    "        \n",
    "        deriva_dict[\"dloss_dw11\"] = x1 * dcost_dz11\n",
    "        deriva_dict[\"dloss_dw12\"] = x2 * dcost_dz11\n",
    "        deriva_dict[\"dloss_db11\"] = dcost_dz11\n",
    "        \n",
    "        deriva_dict[\"dloss_dw13\"] = x1 * dcost_dz12\n",
    "        deriva_dict[\"dloss_dw14\"] = x2 * dcost_dz12\n",
    "        deriva_dict[\"dloss_db12\"] = dcost_dz12\n",
    "        \n",
    "        return deriva_dict\n",
    "    \n",
    "    def get_prob_class(self, x1, x2):\n",
    "        prob = self.forward_prop(x1, x2)[\"a2\"]\n",
    "        class_ = self.encode_class(prob)\n",
    "        return prob, class_\n",
    "    \n",
    "    def encode_class(self, x):\n",
    "        return 1 if x>0.5 else 0\n",
    "    \n",
    "    def get_accuracy_cost(self, X, y):\n",
    "        n = X.shape[0]\n",
    "        n_correct = 0\n",
    "        cost = 0\n",
    "        for i in range(n):\n",
    "            x1, x2 = X[i]\n",
    "            prediction = self.get_prob_class(x1, x2)\n",
    "            if prediction[1] == y[i][0]:\n",
    "                n_correct += 1\n",
    "            cost += self.binary_cross_entropy(prediction[0], y[i][0])\n",
    "        return n_correct/n, cost/n\n",
    "\n",
    "    def fit(self, X, y, alpha, epochs):\n",
    "        n, m = X.shape\n",
    "        \n",
    "        self.initialize()\n",
    "        costs = []\n",
    "\n",
    "        for i in range(1, epochs+1):\n",
    "            # Loop to iterate based on specified epoch\n",
    "            \n",
    "            dcost_dw21 = 0\n",
    "            dcost_dw22 = 0\n",
    "            dcost_db2 = 0\n",
    "            dcost_dw11 = 0\n",
    "            dcost_dw12 = 0\n",
    "            dcost_db11 = 0\n",
    "            dcost_dw13 = 0\n",
    "            dcost_dw14 = 0\n",
    "            dcost_db12 = 0\n",
    "            \n",
    "            for j in range(n):\n",
    "                # Loop to find derivatives for each example\n",
    "                \n",
    "                x1 , x2 = X[j]\n",
    "                y_true = y[j][0]\n",
    "                forward_prop = self.forward_prop(x1, x2)\n",
    "                back_prop = self.back_prop(x1, x2, y_true, forward_prop)\n",
    "                \n",
    "                dcost_dw21 += back_prop[\"dloss_dw21\"]\n",
    "                dcost_dw22 += back_prop[\"dloss_dw22\"]\n",
    "                dcost_db2 += back_prop[\"dloss_db2\"]\n",
    "                dcost_dw11 += back_prop[\"dloss_dw11\"]\n",
    "                dcost_dw12 += back_prop[\"dloss_dw12\"]\n",
    "                dcost_db11 += back_prop[\"dloss_db11\"]\n",
    "                dcost_dw13 += back_prop[\"dloss_dw13\"]\n",
    "                dcost_dw14 += back_prop[\"dloss_dw14\"]\n",
    "                dcost_db12 += back_prop[\"dloss_db12\"]\n",
    "            \n",
    "            # The parameter update process\n",
    "            self.w21 -= alpha*(1/n)*dcost_dw21 \n",
    "            self.w22 -= alpha*(1/n)*dcost_dw22 \n",
    "            self.b2  -= alpha*(1/n)*dcost_db2\n",
    "            self.w11 -= alpha*(1/n)*dcost_dw11 \n",
    "            self.w12 -= alpha*(1/n)*dcost_dw12 \n",
    "            self.b11 -= alpha*(1/n)*dcost_db11\n",
    "            self.w13 -= alpha*(1/n)*dcost_dw13\n",
    "            self.w14 -= alpha*(1/n)*dcost_dw14\n",
    "            self.b12 -= alpha*(1/n)*dcost_db12\n",
    "            \n",
    "            accuracy, cost = self.get_accuracy_cost(X, y)\n",
    "            costs.append(cost)\n",
    "            \n",
    "            print(f\"epoch: {i}, cost: {cost:.4f}, accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d3e8e3",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3e3aaaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, cost: 0.9117, accuracy: 36.48%\n",
      "epoch: 2, cost: 0.8874, accuracy: 36.48%\n",
      "epoch: 3, cost: 0.8654, accuracy: 36.48%\n",
      "epoch: 4, cost: 0.8454, accuracy: 36.48%\n",
      "epoch: 5, cost: 0.8273, accuracy: 36.48%\n",
      "epoch: 6, cost: 0.8107, accuracy: 36.48%\n",
      "epoch: 7, cost: 0.7955, accuracy: 36.48%\n",
      "epoch: 8, cost: 0.7816, accuracy: 36.48%\n",
      "epoch: 9, cost: 0.7688, accuracy: 36.48%\n",
      "epoch: 10, cost: 0.7571, accuracy: 36.48%\n",
      "epoch: 11, cost: 0.7463, accuracy: 36.48%\n",
      "epoch: 12, cost: 0.7364, accuracy: 36.48%\n",
      "epoch: 13, cost: 0.7271, accuracy: 36.48%\n",
      "epoch: 14, cost: 0.7185, accuracy: 62.42%\n",
      "epoch: 15, cost: 0.7105, accuracy: 63.96%\n",
      "epoch: 16, cost: 0.7029, accuracy: 64.62%\n",
      "epoch: 17, cost: 0.6959, accuracy: 65.71%\n",
      "epoch: 18, cost: 0.6893, accuracy: 67.03%\n",
      "epoch: 19, cost: 0.6831, accuracy: 67.69%\n",
      "epoch: 20, cost: 0.6772, accuracy: 68.57%\n",
      "epoch: 21, cost: 0.6717, accuracy: 69.45%\n",
      "epoch: 22, cost: 0.6664, accuracy: 71.21%\n",
      "epoch: 23, cost: 0.6614, accuracy: 71.65%\n",
      "epoch: 24, cost: 0.6567, accuracy: 71.87%\n",
      "epoch: 25, cost: 0.6521, accuracy: 72.09%\n",
      "epoch: 26, cost: 0.6479, accuracy: 72.53%\n",
      "epoch: 27, cost: 0.6437, accuracy: 73.19%\n",
      "epoch: 28, cost: 0.6398, accuracy: 73.41%\n",
      "epoch: 29, cost: 0.6360, accuracy: 74.29%\n",
      "epoch: 30, cost: 0.6323, accuracy: 73.63%\n",
      "epoch: 31, cost: 0.6288, accuracy: 73.63%\n",
      "epoch: 32, cost: 0.6254, accuracy: 73.85%\n",
      "epoch: 33, cost: 0.6221, accuracy: 73.41%\n",
      "epoch: 34, cost: 0.6188, accuracy: 73.63%\n",
      "epoch: 35, cost: 0.6157, accuracy: 74.07%\n",
      "epoch: 36, cost: 0.6126, accuracy: 75.16%\n",
      "epoch: 37, cost: 0.6096, accuracy: 74.73%\n",
      "epoch: 38, cost: 0.6065, accuracy: 75.60%\n",
      "epoch: 39, cost: 0.6035, accuracy: 75.82%\n",
      "epoch: 40, cost: 0.6005, accuracy: 75.82%\n",
      "epoch: 41, cost: 0.5976, accuracy: 76.04%\n",
      "epoch: 42, cost: 0.5947, accuracy: 76.48%\n",
      "epoch: 43, cost: 0.5918, accuracy: 77.36%\n",
      "epoch: 44, cost: 0.5889, accuracy: 77.36%\n",
      "epoch: 45, cost: 0.5860, accuracy: 78.02%\n",
      "epoch: 46, cost: 0.5832, accuracy: 78.24%\n",
      "epoch: 47, cost: 0.5804, accuracy: 78.24%\n",
      "epoch: 48, cost: 0.5776, accuracy: 78.90%\n",
      "epoch: 49, cost: 0.5748, accuracy: 79.34%\n",
      "epoch: 50, cost: 0.5720, accuracy: 79.34%\n",
      "epoch: 51, cost: 0.5692, accuracy: 79.34%\n",
      "epoch: 52, cost: 0.5663, accuracy: 79.56%\n",
      "epoch: 53, cost: 0.5635, accuracy: 79.56%\n",
      "epoch: 54, cost: 0.5607, accuracy: 79.34%\n",
      "epoch: 55, cost: 0.5579, accuracy: 79.56%\n",
      "epoch: 56, cost: 0.5551, accuracy: 80.00%\n",
      "epoch: 57, cost: 0.5522, accuracy: 80.00%\n",
      "epoch: 58, cost: 0.5494, accuracy: 80.00%\n",
      "epoch: 59, cost: 0.5465, accuracy: 80.22%\n",
      "epoch: 60, cost: 0.5437, accuracy: 80.66%\n",
      "epoch: 61, cost: 0.5408, accuracy: 80.66%\n",
      "epoch: 62, cost: 0.5379, accuracy: 80.88%\n",
      "epoch: 63, cost: 0.5350, accuracy: 81.10%\n",
      "epoch: 64, cost: 0.5321, accuracy: 81.32%\n",
      "epoch: 65, cost: 0.5291, accuracy: 81.32%\n",
      "epoch: 66, cost: 0.5262, accuracy: 81.54%\n",
      "epoch: 67, cost: 0.5233, accuracy: 82.20%\n",
      "epoch: 68, cost: 0.5203, accuracy: 82.86%\n",
      "epoch: 69, cost: 0.5173, accuracy: 83.08%\n",
      "epoch: 70, cost: 0.5144, accuracy: 83.30%\n",
      "epoch: 71, cost: 0.5114, accuracy: 83.74%\n",
      "epoch: 72, cost: 0.5084, accuracy: 83.74%\n",
      "epoch: 73, cost: 0.5055, accuracy: 83.74%\n",
      "epoch: 74, cost: 0.5026, accuracy: 84.40%\n",
      "epoch: 75, cost: 0.4997, accuracy: 84.18%\n",
      "epoch: 76, cost: 0.4968, accuracy: 84.18%\n",
      "epoch: 77, cost: 0.4939, accuracy: 83.96%\n",
      "epoch: 78, cost: 0.4910, accuracy: 84.18%\n",
      "epoch: 79, cost: 0.4881, accuracy: 84.40%\n",
      "epoch: 80, cost: 0.4853, accuracy: 84.40%\n",
      "epoch: 81, cost: 0.4824, accuracy: 84.40%\n",
      "epoch: 82, cost: 0.4796, accuracy: 84.62%\n",
      "epoch: 83, cost: 0.4768, accuracy: 84.84%\n",
      "epoch: 84, cost: 0.4740, accuracy: 85.05%\n",
      "epoch: 85, cost: 0.4713, accuracy: 85.27%\n",
      "epoch: 86, cost: 0.4686, accuracy: 85.27%\n",
      "epoch: 87, cost: 0.4659, accuracy: 85.49%\n",
      "epoch: 88, cost: 0.4633, accuracy: 85.71%\n",
      "epoch: 89, cost: 0.4606, accuracy: 85.71%\n",
      "epoch: 90, cost: 0.4581, accuracy: 85.93%\n",
      "epoch: 91, cost: 0.4555, accuracy: 85.93%\n",
      "epoch: 92, cost: 0.4530, accuracy: 86.15%\n",
      "epoch: 93, cost: 0.4504, accuracy: 86.15%\n",
      "epoch: 94, cost: 0.4479, accuracy: 86.15%\n",
      "epoch: 95, cost: 0.4454, accuracy: 86.37%\n",
      "epoch: 96, cost: 0.4429, accuracy: 86.59%\n",
      "epoch: 97, cost: 0.4405, accuracy: 86.59%\n",
      "epoch: 98, cost: 0.4380, accuracy: 86.59%\n",
      "epoch: 99, cost: 0.4356, accuracy: 86.59%\n",
      "epoch: 100, cost: 0.4333, accuracy: 86.81%\n",
      "epoch: 101, cost: 0.4310, accuracy: 86.59%\n",
      "epoch: 102, cost: 0.4287, accuracy: 86.81%\n",
      "epoch: 103, cost: 0.4264, accuracy: 87.03%\n",
      "epoch: 104, cost: 0.4242, accuracy: 87.25%\n",
      "epoch: 105, cost: 0.4220, accuracy: 87.25%\n",
      "epoch: 106, cost: 0.4199, accuracy: 87.25%\n",
      "epoch: 107, cost: 0.4177, accuracy: 87.47%\n",
      "epoch: 108, cost: 0.4156, accuracy: 87.47%\n",
      "epoch: 109, cost: 0.4135, accuracy: 87.69%\n",
      "epoch: 110, cost: 0.4115, accuracy: 87.47%\n",
      "epoch: 111, cost: 0.4094, accuracy: 87.47%\n",
      "epoch: 112, cost: 0.4074, accuracy: 87.47%\n",
      "epoch: 113, cost: 0.4055, accuracy: 87.47%\n",
      "epoch: 114, cost: 0.4035, accuracy: 87.91%\n",
      "epoch: 115, cost: 0.4016, accuracy: 88.13%\n",
      "epoch: 116, cost: 0.3997, accuracy: 88.13%\n",
      "epoch: 117, cost: 0.3979, accuracy: 88.35%\n",
      "epoch: 118, cost: 0.3961, accuracy: 88.57%\n",
      "epoch: 119, cost: 0.3943, accuracy: 88.57%\n",
      "epoch: 120, cost: 0.3925, accuracy: 88.57%\n",
      "epoch: 121, cost: 0.3907, accuracy: 88.57%\n",
      "epoch: 122, cost: 0.3890, accuracy: 88.57%\n",
      "epoch: 123, cost: 0.3873, accuracy: 88.57%\n",
      "epoch: 124, cost: 0.3856, accuracy: 88.57%\n",
      "epoch: 125, cost: 0.3839, accuracy: 88.57%\n",
      "epoch: 126, cost: 0.3823, accuracy: 88.35%\n",
      "epoch: 127, cost: 0.3807, accuracy: 88.57%\n",
      "epoch: 128, cost: 0.3791, accuracy: 88.57%\n",
      "epoch: 129, cost: 0.3775, accuracy: 88.79%\n",
      "epoch: 130, cost: 0.3760, accuracy: 88.79%\n",
      "epoch: 131, cost: 0.3744, accuracy: 88.79%\n",
      "epoch: 132, cost: 0.3729, accuracy: 88.79%\n",
      "epoch: 133, cost: 0.3715, accuracy: 89.01%\n",
      "epoch: 134, cost: 0.3700, accuracy: 89.23%\n",
      "epoch: 135, cost: 0.3685, accuracy: 89.23%\n",
      "epoch: 136, cost: 0.3671, accuracy: 89.45%\n",
      "epoch: 137, cost: 0.3656, accuracy: 89.45%\n",
      "epoch: 138, cost: 0.3642, accuracy: 89.45%\n",
      "epoch: 139, cost: 0.3628, accuracy: 89.45%\n",
      "epoch: 140, cost: 0.3615, accuracy: 89.45%\n",
      "epoch: 141, cost: 0.3601, accuracy: 89.67%\n",
      "epoch: 142, cost: 0.3588, accuracy: 89.67%\n",
      "epoch: 143, cost: 0.3575, accuracy: 89.67%\n",
      "epoch: 144, cost: 0.3562, accuracy: 89.67%\n",
      "epoch: 145, cost: 0.3549, accuracy: 89.67%\n",
      "epoch: 146, cost: 0.3536, accuracy: 89.67%\n",
      "epoch: 147, cost: 0.3524, accuracy: 89.67%\n",
      "epoch: 148, cost: 0.3511, accuracy: 89.89%\n",
      "epoch: 149, cost: 0.3499, accuracy: 89.89%\n",
      "epoch: 150, cost: 0.3487, accuracy: 89.89%\n",
      "epoch: 151, cost: 0.3475, accuracy: 89.67%\n",
      "epoch: 152, cost: 0.3463, accuracy: 89.67%\n",
      "epoch: 153, cost: 0.3451, accuracy: 89.67%\n",
      "epoch: 154, cost: 0.3440, accuracy: 89.67%\n",
      "epoch: 155, cost: 0.3429, accuracy: 89.67%\n",
      "epoch: 156, cost: 0.3418, accuracy: 89.67%\n",
      "epoch: 157, cost: 0.3407, accuracy: 89.67%\n",
      "epoch: 158, cost: 0.3397, accuracy: 89.67%\n",
      "epoch: 159, cost: 0.3386, accuracy: 89.67%\n",
      "epoch: 160, cost: 0.3376, accuracy: 89.67%\n",
      "epoch: 161, cost: 0.3366, accuracy: 89.67%\n",
      "epoch: 162, cost: 0.3356, accuracy: 89.67%\n",
      "epoch: 163, cost: 0.3346, accuracy: 89.67%\n",
      "epoch: 164, cost: 0.3336, accuracy: 89.67%\n",
      "epoch: 165, cost: 0.3327, accuracy: 89.67%\n",
      "epoch: 166, cost: 0.3317, accuracy: 89.67%\n",
      "epoch: 167, cost: 0.3308, accuracy: 89.67%\n",
      "epoch: 168, cost: 0.3299, accuracy: 89.67%\n",
      "epoch: 169, cost: 0.3290, accuracy: 89.67%\n",
      "epoch: 170, cost: 0.3281, accuracy: 89.67%\n",
      "epoch: 171, cost: 0.3273, accuracy: 89.67%\n",
      "epoch: 172, cost: 0.3264, accuracy: 89.67%\n",
      "epoch: 173, cost: 0.3256, accuracy: 89.45%\n",
      "epoch: 174, cost: 0.3248, accuracy: 89.67%\n",
      "epoch: 175, cost: 0.3240, accuracy: 89.67%\n",
      "epoch: 176, cost: 0.3232, accuracy: 89.67%\n",
      "epoch: 177, cost: 0.3224, accuracy: 89.67%\n",
      "epoch: 178, cost: 0.3216, accuracy: 89.67%\n",
      "epoch: 179, cost: 0.3209, accuracy: 89.67%\n",
      "epoch: 180, cost: 0.3201, accuracy: 89.67%\n",
      "epoch: 181, cost: 0.3194, accuracy: 89.89%\n",
      "epoch: 182, cost: 0.3186, accuracy: 89.89%\n",
      "epoch: 183, cost: 0.3179, accuracy: 89.89%\n",
      "epoch: 184, cost: 0.3172, accuracy: 89.89%\n",
      "epoch: 185, cost: 0.3165, accuracy: 89.89%\n",
      "epoch: 186, cost: 0.3159, accuracy: 89.89%\n",
      "epoch: 187, cost: 0.3152, accuracy: 90.11%\n",
      "epoch: 188, cost: 0.3145, accuracy: 90.11%\n",
      "epoch: 189, cost: 0.3139, accuracy: 90.11%\n",
      "epoch: 190, cost: 0.3133, accuracy: 90.11%\n",
      "epoch: 191, cost: 0.3127, accuracy: 90.11%\n",
      "epoch: 192, cost: 0.3120, accuracy: 90.11%\n",
      "epoch: 193, cost: 0.3114, accuracy: 90.33%\n",
      "epoch: 194, cost: 0.3108, accuracy: 90.33%\n",
      "epoch: 195, cost: 0.3103, accuracy: 90.33%\n",
      "epoch: 196, cost: 0.3097, accuracy: 90.33%\n",
      "epoch: 197, cost: 0.3091, accuracy: 90.33%\n",
      "epoch: 198, cost: 0.3085, accuracy: 90.33%\n",
      "epoch: 199, cost: 0.3080, accuracy: 90.33%\n",
      "epoch: 200, cost: 0.3074, accuracy: 90.33%\n"
     ]
    }
   ],
   "source": [
    "classifier = NeuralNetwork()\n",
    "classifier.fit(X_train, y_train, 0.1, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598580c2",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8a6dd82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: 0.271\n",
      "accuracy: 0.912\n"
     ]
    }
   ],
   "source": [
    "result = classifier.get_accuracy_cost(X_test, y_test)\n",
    "\n",
    "print(f\"cost: {result[1]:.3f}\")\n",
    "print(f\"accuracy: {result[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe28c3c",
   "metadata": {},
   "source": [
    "## Bonus: Vanilla gradient descent vs mini batch gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c0b02f",
   "metadata": {},
   "source": [
    "The following is the same neural network with the same architecture but with mini batch gradient descent instead of vanilla gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65243079",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork_batch():\n",
    "    \n",
    "    def initialize(self):\n",
    "        self.w11, self.w12, self.w13, self.w14, self.w21, self.w22, self.b11, self.b12, self.b2 = np.random.randn(9)\n",
    "    \n",
    "    def relu(self, x):\n",
    "        return np.maximum(x, 0)\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def binary_cross_entropy(self, x, y_true):\n",
    "        return -(y_true * np.log(x) + (1 - y_true) * np.log(1 - x))\n",
    "    \n",
    "    def derivative_relu(self, x):\n",
    "        return 1 if x>0 else 0\n",
    "    \n",
    "    def forward_prop(self, x1, x2):\n",
    "        forward_dict = {} \n",
    "        \n",
    "        # hidden layer\n",
    "        forward_dict[\"z11\"] = self.w11 * x1 + self.w12 * x2 + self.b11\n",
    "        forward_dict[\"z12\"] = self.w13 * x1 + self.w14 * x2 + self.b12\n",
    "        forward_dict[\"a11\"] = self.relu(forward_dict[\"z11\"])\n",
    "        forward_dict[\"a12\"] = self.relu(forward_dict[\"z12\"])\n",
    "        \n",
    "        # output layer\n",
    "        forward_dict[\"z2\"] = self.w21 * forward_dict[\"a11\"] + self.w22 * forward_dict[\"a12\"] + self.b2\n",
    "        forward_dict[\"a2\"] = self.sigmoid(forward_dict[\"z2\"])\n",
    "        \n",
    "        return forward_dict\n",
    "\n",
    "    def back_prop(self, x1, x2, y_true, forward_dict):\n",
    "        # gradient will be calculated for each training example and averaged later#\n",
    "        \n",
    "        deriva_dict = {}\n",
    "        \n",
    "        # output layer\n",
    "        error = forward_dict[\"a2\"] - y_true\n",
    "        \n",
    "        deriva_dict[\"dloss_dw21\"] = forward_dict[\"a11\"] * error\n",
    "        deriva_dict[\"dloss_dw22\"] = forward_dict[\"a12\"] * error\n",
    "        deriva_dict[\"dloss_db2\"] = error\n",
    "        \n",
    "        # hidden layer\n",
    "        dcost_dz11 = self.derivative_relu(forward_dict[\"z11\"]) * self.w21 * error\n",
    "        dcost_dz12 = self.derivative_relu(forward_dict[\"z12\"]) * self.w22 * error\n",
    "        \n",
    "        deriva_dict[\"dloss_dw11\"] = x1 * dcost_dz11\n",
    "        deriva_dict[\"dloss_dw12\"] = x2 * dcost_dz11\n",
    "        deriva_dict[\"dloss_db11\"] = dcost_dz11\n",
    "        \n",
    "        deriva_dict[\"dloss_dw13\"] = x1 * dcost_dz12\n",
    "        deriva_dict[\"dloss_dw14\"] = x2 * dcost_dz12\n",
    "        deriva_dict[\"dloss_db12\"] = dcost_dz12\n",
    "        \n",
    "        return deriva_dict\n",
    "    \n",
    "    def get_prob_class(self, x1, x2):\n",
    "        prob = self.forward_prop(x1, x2)[\"a2\"]\n",
    "        class_ = self.encode_class(prob)\n",
    "        return prob, class_\n",
    "    \n",
    "    def encode_class(self, x):\n",
    "        return 1 if x>0.5 else 0\n",
    "    \n",
    "    def get_accuracy_cost(self, X, y):\n",
    "        n = X.shape[0]\n",
    "        n_correct = 0\n",
    "        cost_total = 0\n",
    "        for i in range(n):\n",
    "            x1, x2 = X[i]\n",
    "            prediction = self.get_prob_class(x1, x2)\n",
    "            if prediction[1] == y[i][0]:\n",
    "                n_correct += 1\n",
    "            cost_total += self.binary_cross_entropy(prediction[0], y[i][0])\n",
    "        return n_correct/n, cost_total/n\n",
    "\n",
    "    def fit(self, X, y, alpha, epochs, batch_size=32):\n",
    "        n, m = X.shape\n",
    "        combined = np.hstack([X, y])\n",
    "        self.initialize()\n",
    "        n_iter_batch = np.ceil(n/batch_size)  # Number of training iteration for one epoch\n",
    "        \n",
    "\n",
    "        for i in range(1, epochs+1):\n",
    "            dcost_dw21 = 0\n",
    "            dcost_dw22 = 0\n",
    "            dcost_db2 = 0\n",
    "            dcost_dw11 = 0\n",
    "            dcost_dw12 = 0\n",
    "            dcost_db11 = 0\n",
    "            dcost_dw13 = 0\n",
    "            dcost_dw14 = 0\n",
    "            dcost_db12 = 0\n",
    "            \n",
    "            #Shuffled the dataset before splitting\n",
    "            combined_shuffled = np.random.permutation(combined)\n",
    "            X_shuffled = combined_shuffled[:, 0:-1]\n",
    "            y_shuffled = combined_shuffled[:, -1].reshape(-1, 1)\n",
    "            \n",
    "            costs_batch = 0\n",
    "            accuracies_batch = 0\n",
    "            for k in tqdm(range(0, n, batch_size), position=0):\n",
    "                X_batch = X_shuffled[k: k+batch_size]\n",
    "                y_batch = y_shuffled[k: k+batch_size]\n",
    "                n_batch = X_batch.shape[0]\n",
    "            \n",
    "                for j in range(n_batch):\n",
    "                    x1 , x2 = X_batch[j]\n",
    "                    y_true = y_batch[j][0]\n",
    "                    forward_prop = self.forward_prop(x1, x2)\n",
    "                    back_prop = self.back_prop(x1, x2, y_true, forward_prop)\n",
    "\n",
    "                    dcost_dw21 += back_prop[\"dloss_dw21\"]\n",
    "                    dcost_dw22 += back_prop[\"dloss_dw22\"]\n",
    "                    dcost_db2 += back_prop[\"dloss_db2\"]\n",
    "                    dcost_dw11 += back_prop[\"dloss_dw11\"]\n",
    "                    dcost_dw12 += back_prop[\"dloss_dw12\"]\n",
    "                    dcost_db11 += back_prop[\"dloss_db11\"]\n",
    "                    dcost_dw13 += back_prop[\"dloss_dw13\"]\n",
    "                    dcost_dw14 += back_prop[\"dloss_dw14\"]\n",
    "                    dcost_db12 += back_prop[\"dloss_db12\"]\n",
    "\n",
    "                self.w21 -= alpha*(1/n)*dcost_dw21 \n",
    "                self.w22 -= alpha*(1/n)*dcost_dw22 \n",
    "                self.b2  -= alpha*(1/n)*dcost_db2\n",
    "                self.w11 -= alpha*(1/n)*dcost_dw11 \n",
    "                self.w12 -= alpha*(1/n)*dcost_dw12 \n",
    "                self.b11 -= alpha*(1/n)*dcost_db11\n",
    "                self.w13 -= alpha*(1/n)*dcost_dw13\n",
    "                self.w14 -= alpha*(1/n)*dcost_dw14\n",
    "                self.b12 -= alpha*(1/n)*dcost_db12\n",
    "\n",
    "                accuracy, cost = self.get_accuracy_cost(X_batch, y_batch)\n",
    "                costs_batch += cost\n",
    "                accuracies_batch += accuracy\n",
    "            \n",
    "            # Reported cost and accuracy are averaged across the mini batch\n",
    "            # of a given epoch\n",
    "            epoch_cost = costs_batch/n_iter_batch\n",
    "            epoch_accuracy = accuracies_batch/n_iter_batch\n",
    "            print(f\"epoch: {i}, cost: {epoch_cost:.4f}, accuracy: {epoch_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672481ba",
   "metadata": {},
   "source": [
    "### Training using small epoch (30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc64ef6",
   "metadata": {},
   "source": [
    "#### With mini batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d365253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 219.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, cost: 0.7474, accuracy: 0.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 397.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, cost: 0.6676, accuracy: 0.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 408.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, cost: 0.5986, accuracy: 0.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 397.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, cost: 0.5489, accuracy: 0.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 264.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, cost: 0.4603, accuracy: 0.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 335.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, cost: 0.4302, accuracy: 0.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 324.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, cost: 0.4108, accuracy: 0.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 299.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, cost: 0.3749, accuracy: 0.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 235.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, cost: 0.3669, accuracy: 0.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 224.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, cost: 0.3573, accuracy: 0.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 297.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, cost: 0.3637, accuracy: 0.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 274.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, cost: 0.3343, accuracy: 0.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 259.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, cost: 0.3280, accuracy: 0.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 413.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14, cost: 0.3281, accuracy: 0.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 271.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15, cost: 0.3102, accuracy: 0.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 395.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16, cost: 0.3172, accuracy: 0.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 305.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17, cost: 0.3055, accuracy: 0.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 306.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18, cost: 0.3066, accuracy: 0.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 274.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19, cost: 0.3021, accuracy: 0.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 321.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20, cost: 0.2961, accuracy: 0.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 292.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21, cost: 0.2993, accuracy: 0.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 311.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22, cost: 0.3113, accuracy: 0.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 296.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23, cost: 0.2980, accuracy: 0.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 409.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24, cost: 0.2916, accuracy: 0.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 284.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25, cost: 0.2856, accuracy: 0.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 326.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26, cost: 0.2798, accuracy: 0.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 358.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27, cost: 0.2757, accuracy: 0.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 417.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28, cost: 0.2767, accuracy: 0.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 380.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29, cost: 0.2776, accuracy: 0.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 410.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30, cost: 0.2703, accuracy: 0.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_batch = NeuralNetwork_batch()\n",
    "classifier_batch.fit(X_train, y_train, 0.1, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89f97e3",
   "metadata": {},
   "source": [
    "#### Without mini batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15e1457e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, cost: 1.2479, accuracy: 63.52%\n",
      "epoch: 2, cost: 1.1778, accuracy: 63.52%\n",
      "epoch: 3, cost: 1.1152, accuracy: 63.52%\n",
      "epoch: 4, cost: 1.0593, accuracy: 63.52%\n",
      "epoch: 5, cost: 1.0093, accuracy: 63.52%\n",
      "epoch: 6, cost: 0.9645, accuracy: 63.52%\n",
      "epoch: 7, cost: 0.9243, accuracy: 63.52%\n",
      "epoch: 8, cost: 0.8883, accuracy: 63.52%\n",
      "epoch: 9, cost: 0.8559, accuracy: 63.52%\n",
      "epoch: 10, cost: 0.8268, accuracy: 63.52%\n",
      "epoch: 11, cost: 0.8004, accuracy: 63.52%\n",
      "epoch: 12, cost: 0.7764, accuracy: 63.52%\n",
      "epoch: 13, cost: 0.7547, accuracy: 63.52%\n",
      "epoch: 14, cost: 0.7349, accuracy: 63.52%\n",
      "epoch: 15, cost: 0.7168, accuracy: 63.52%\n",
      "epoch: 16, cost: 0.7002, accuracy: 63.52%\n",
      "epoch: 17, cost: 0.6850, accuracy: 63.52%\n",
      "epoch: 18, cost: 0.6710, accuracy: 63.52%\n",
      "epoch: 19, cost: 0.6580, accuracy: 63.52%\n",
      "epoch: 20, cost: 0.6459, accuracy: 63.52%\n",
      "epoch: 21, cost: 0.6347, accuracy: 63.52%\n",
      "epoch: 22, cost: 0.6242, accuracy: 63.52%\n",
      "epoch: 23, cost: 0.6144, accuracy: 63.52%\n",
      "epoch: 24, cost: 0.6052, accuracy: 63.52%\n",
      "epoch: 25, cost: 0.5965, accuracy: 63.52%\n",
      "epoch: 26, cost: 0.5883, accuracy: 63.52%\n",
      "epoch: 27, cost: 0.5806, accuracy: 63.52%\n",
      "epoch: 28, cost: 0.5732, accuracy: 63.52%\n",
      "epoch: 29, cost: 0.5662, accuracy: 63.52%\n",
      "epoch: 30, cost: 0.5596, accuracy: 63.74%\n"
     ]
    }
   ],
   "source": [
    "classifier = NeuralNetwork()\n",
    "classifier.fit(X_train, y_train, 0.1, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93f3701",
   "metadata": {},
   "source": [
    "### Evaluation & Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd367ec",
   "metadata": {},
   "source": [
    "#### Without mini batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "692f6920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: 0.582\n",
      "accuracy: 0.596\n"
     ]
    }
   ],
   "source": [
    "classifier_vanilla = classifier.get_accuracy_cost(X_test, y_test)\n",
    "\n",
    "print(f\"cost: {classifier_vanilla[1]:.3f}\")\n",
    "print(f\"accuracy: {classifier_vanilla[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81337c3",
   "metadata": {},
   "source": [
    "#### Without mini batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b9d9374",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: 0.262\n",
      "accuracy: 0.895\n"
     ]
    }
   ],
   "source": [
    "classifier_batch = classifier_batch.get_accuracy_cost(X_test, y_test)\n",
    "\n",
    "print(f\"cost: {classifier_batch[1]:.3f}\")\n",
    "print(f\"accuracy: {classifier_batch[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebcf361",
   "metadata": {},
   "source": [
    "It appears that, in the long run, mini batch gradient descent can achieve better metrics using less epoch, hence more efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b479547",
   "metadata": {},
   "source": [
    "# That's it. not bad at all :p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
